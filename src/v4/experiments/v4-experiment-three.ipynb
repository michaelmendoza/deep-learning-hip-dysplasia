{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f471bf",
   "metadata": {},
   "source": [
    "Hip Dysplasia Classification\n",
    "\n",
    "v4 - Experiment One - Based on code from ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4cf13",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01706342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import time\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from data_loader import DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8334ca",
   "metadata": {},
   "source": [
    "Model Architecture is a ResNET (Let's try with Keras ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529e725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(HEIGHT, WIDTH, CHANNELS, NUM_OUTPUTS):\n",
    "    Network = tf.keras.applications.ResNet50V2\n",
    "    base_model = Network(weights = None, \n",
    "                        include_top = False, \n",
    "                        input_shape = (HEIGHT, WIDTH, CHANNELS),\n",
    "                        pooling='max')\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    x = layers.Flatten()(base_model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(NUM_OUTPUTS, activation='softmax')(x)\n",
    "    model = keras.Model(inputs = base_model.input, outputs = x)\n",
    "    model.base_model = base_model # Save ref to base_model \n",
    "        \n",
    "    layer_count = sum([model.layers[i].name.count('conv2d') for i in range(len(model.layers))])\n",
    "    print(\"Number of conv2d layers in the model: \", layer_count)\n",
    "    print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e28ed3",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840adb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "epochs = 200\n",
    "batch_size = 128 \n",
    "\n",
    "# Network Parameters\n",
    "useTransferLearning = False\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "CHANNELS = 3 if useTransferLearning else 1 \n",
    "NUM_OUTPUTS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27877e8",
   "metadata": {},
   "source": [
    "Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3939f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Trains model using input dataset. Currently uses Adam optimizer, and early stopping in training. Outputs model, train_history, and test metrics\n",
    "'''\n",
    "\n",
    "def TrainResNet(dataset):\n",
    "    metrics = [\n",
    "        'acc',\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    ]\n",
    "    \n",
    "    earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', verbose=1, patience=25)\n",
    "\n",
    "    model = resnet(HEIGHT, WIDTH, CHANNELS, NUM_OUTPUTS)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=metrics)\n",
    "    model.summary()\n",
    "    \n",
    "    # Train and Evaluate model\n",
    "    training_steps = round(data.train_size / batch_size)\n",
    "    validation_steps = round(data.test_size / batch_size)\n",
    "    train_history = model.fit(dataset.train_dataset, epochs=epochs, steps_per_epoch=training_steps,\n",
    "            validation_data=dataset.valid_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=[earlyStopping])\n",
    "    \n",
    "    # Evaluate Test Data \n",
    "    steps = round(data.test_size / (batch_size))\n",
    "    test_metrics = model.evaluate(dataset.test_dataset, batch_size=batch_size, steps=steps)\n",
    "    \n",
    "    return model, train_history, test_metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d541a",
   "metadata": {},
   "source": [
    "Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f08edb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██                                                                             | 28/1079 [00:00<00:03, 275.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and formating image data ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1079/1079 [00:38<00:00, 27.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: Input Data (863, 500, 500, 1)  Truth Data: (863, 2)\n",
      "Test data size: Input Data (216, 500, 500, 1)  Truth Data: (216, 2)\n",
      "Loading and formating image data: Complete\n",
      "Train Size: 863 Test Size: 216\n",
      "Training ResNet2 ...\n",
      "Number of conv2d layers in the model:  0\n",
      "Number of layers in the base model:  191\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 3200        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 64, 64, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 64, 64, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 64, 64, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 32, 32, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 32, 32, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 32, 32, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 32, 32, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 16, 16, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 16, 16, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 16, 16, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 8, 8, 1024)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 8, 8, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 8, 8, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 8, 8, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 8, 8, 2048)   0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pool (GlobalMaxPooling2D)   (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2048)         8192        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64)           256         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            130         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "resnet50v2 (Functional)         (None, 2048)         23558528                                     \n",
      "==================================================================================================\n",
      "Total params: 24,134,338\n",
      "Trainable params: 24,083,906\n",
      "Non-trainable params: 50,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 20s 1s/step - loss: 1.0217 - acc: 0.4876 - tp: 258.8750 - fp: 268.1250 - tn: 258.8750 - fn: 268.1250 - accuracy: 0.4876 - precision: 0.4876 - recall: 0.4876 - auc: 0.5036 - prc: 0.5079 - val_loss: 0.6818 - val_acc: 0.5898 - val_tp: 151.0000 - val_fp: 105.0000 - val_tn: 151.0000 - val_fn: 105.0000 - val_accuracy: 0.5898 - val_precision: 0.5898 - val_recall: 0.5898 - val_auc: 0.6154 - val_prc: 0.5746\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 5s 612ms/step - loss: 0.8238 - acc: 0.5804 - tp: 309.6250 - fp: 225.6250 - tn: 309.6250 - fn: 225.6250 - accuracy: 0.5804 - precision: 0.5804 - recall: 0.5804 - auc: 0.6184 - prc: 0.6033 - val_loss: 0.7592 - val_acc: 0.2825 - val_tp: 63.0000 - val_fp: 160.0000 - val_tn: 63.0000 - val_fn: 160.0000 - val_accuracy: 0.2825 - val_precision: 0.2825 - val_recall: 0.2825 - val_auc: 0.2906 - val_prc: 0.3817\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 5s 634ms/step - loss: 0.8237 - acc: 0.5685 - tp: 297.8750 - fp: 229.1250 - tn: 297.8750 - fn: 229.1250 - accuracy: 0.5685 - precision: 0.5685 - recall: 0.5685 - auc: 0.6046 - prc: 0.5918 - val_loss: 0.7692 - val_acc: 0.3139 - val_tp: 70.0000 - val_fp: 153.0000 - val_tn: 70.0000 - val_fn: 153.0000 - val_accuracy: 0.3139 - val_precision: 0.3139 - val_recall: 0.3139 - val_auc: 0.3187 - val_prc: 0.4028\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 5s 654ms/step - loss: 0.6818 - acc: 0.6590 - tp: 362.6250 - fp: 180.8750 - tn: 362.6250 - fn: 180.8750 - accuracy: 0.6590 - precision: 0.6590 - recall: 0.6590 - auc: 0.7013 - prc: 0.6894 - val_loss: 0.7836 - val_acc: 0.4102 - val_tp: 105.0000 - val_fp: 151.0000 - val_tn: 105.0000 - val_fn: 151.0000 - val_accuracy: 0.4102 - val_precision: 0.4102 - val_recall: 0.4102 - val_auc: 0.3744 - val_prc: 0.4192\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 5s 625ms/step - loss: 0.5888 - acc: 0.7124 - tp: 392.6250 - fp: 155.0000 - tn: 392.6250 - fn: 155.0000 - accuracy: 0.7124 - precision: 0.7124 - recall: 0.7124 - auc: 0.7862 - prc: 0.7751 - val_loss: 0.7647 - val_acc: 0.3477 - val_tp: 89.0000 - val_fp: 167.0000 - val_tn: 89.0000 - val_fn: 167.0000 - val_accuracy: 0.3477 - val_precision: 0.3477 - val_recall: 0.3477 - val_auc: 0.3301 - val_prc: 0.3954\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 5s 623ms/step - loss: 0.4735 - acc: 0.7839 - tp: 426.6250 - fp: 108.6250 - tn: 426.6250 - fn: 108.6250 - accuracy: 0.7839 - precision: 0.7839 - recall: 0.7839 - auc: 0.8600 - prc: 0.8503 - val_loss: 0.6187 - val_acc: 0.6906 - val_tp: 154.0000 - val_fp: 69.0000 - val_tn: 154.0000 - val_fn: 69.0000 - val_accuracy: 0.6906 - val_precision: 0.6906 - val_recall: 0.6906 - val_auc: 0.6972 - val_prc: 0.6469\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 5s 627ms/step - loss: 0.3187 - acc: 0.8781 - tp: 485.3750 - fp: 66.3750 - tn: 485.3750 - fn: 66.3750 - accuracy: 0.8781 - precision: 0.8781 - recall: 0.8781 - auc: 0.9382 - prc: 0.9374 - val_loss: 0.6669 - val_acc: 0.7085 - val_tp: 158.0000 - val_fp: 65.0000 - val_tn: 158.0000 - val_fn: 65.0000 - val_accuracy: 0.7085 - val_precision: 0.7085 - val_recall: 0.7085 - val_auc: 0.6994 - val_prc: 0.6619\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 5s 618ms/step - loss: 0.1855 - acc: 0.9425 - tp: 514.1250 - fp: 33.5000 - tn: 514.1250 - fn: 33.5000 - accuracy: 0.9425 - precision: 0.9425 - recall: 0.9425 - auc: 0.9834 - prc: 0.9818 - val_loss: 0.8503 - val_acc: 0.6133 - val_tp: 157.0000 - val_fp: 99.0000 - val_tn: 157.0000 - val_fn: 99.0000 - val_accuracy: 0.6133 - val_precision: 0.6133 - val_recall: 0.6133 - val_auc: 0.6840 - val_prc: 0.6564\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 5s 616ms/step - loss: 0.1532 - acc: 0.9484 - tp: 520.0000 - fp: 27.6250 - tn: 520.0000 - fn: 27.6250 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - auc: 0.9893 - prc: 0.9897 - val_loss: 0.7380 - val_acc: 0.6906 - val_tp: 154.0000 - val_fp: 69.0000 - val_tn: 154.0000 - val_fn: 69.0000 - val_accuracy: 0.6906 - val_precision: 0.6906 - val_recall: 0.6906 - val_auc: 0.7267 - val_prc: 0.7085\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 5s 616ms/step - loss: 0.1040 - acc: 0.9716 - tp: 514.2500 - fp: 16.8750 - tn: 514.2500 - fn: 16.8750 - accuracy: 0.9716 - precision: 0.9716 - recall: 0.9716 - auc: 0.9932 - prc: 0.9929 - val_loss: 0.7817 - val_acc: 0.6771 - val_tp: 151.0000 - val_fp: 72.0000 - val_tn: 151.0000 - val_fn: 72.0000 - val_accuracy: 0.6771 - val_precision: 0.6771 - val_recall: 0.6771 - val_auc: 0.7144 - val_prc: 0.6687\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 5s 642ms/step - loss: 0.0938 - acc: 0.9802 - tp: 514.3750 - fp: 12.6250 - tn: 514.3750 - fn: 12.6250 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - auc: 0.9953 - prc: 0.9954 - val_loss: 0.9113 - val_acc: 0.6906 - val_tp: 154.0000 - val_fp: 69.0000 - val_tn: 154.0000 - val_fn: 69.0000 - val_accuracy: 0.6906 - val_precision: 0.6906 - val_recall: 0.6906 - val_auc: 0.7148 - val_prc: 0.6963\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 5s 623ms/step - loss: 0.1115 - acc: 0.9729 - tp: 525.3750 - fp: 14.0000 - tn: 525.3750 - fn: 14.0000 - accuracy: 0.9729 - precision: 0.9729 - recall: 0.9729 - auc: 0.9885 - prc: 0.9859 - val_loss: 1.0737 - val_acc: 0.6641 - val_tp: 170.0000 - val_fp: 86.0000 - val_tn: 170.0000 - val_fn: 86.0000 - val_accuracy: 0.6641 - val_precision: 0.6641 - val_recall: 0.6641 - val_auc: 0.7313 - val_prc: 0.7102\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 5s 643ms/step - loss: 0.0487 - acc: 0.9930 - tp: 522.6250 - fp: 4.3750 - tn: 522.6250 - fn: 4.3750 - accuracy: 0.9930 - precision: 0.9930 - recall: 0.9930 - auc: 0.9990 - prc: 0.9990 - val_loss: 1.1308 - val_acc: 0.6771 - val_tp: 151.0000 - val_fp: 72.0000 - val_tn: 151.0000 - val_fn: 72.0000 - val_accuracy: 0.6771 - val_precision: 0.6771 - val_recall: 0.6771 - val_auc: 0.6936 - val_prc: 0.6551\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 5s 650ms/step - loss: 0.0424 - acc: 0.9906 - tp: 521.7500 - fp: 5.2500 - tn: 521.7500 - fn: 5.2500 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9996 - prc: 0.9996 - val_loss: 1.4174 - val_acc: 0.5820 - val_tp: 149.0000 - val_fp: 107.0000 - val_tn: 149.0000 - val_fn: 107.0000 - val_accuracy: 0.5820 - val_precision: 0.5820 - val_recall: 0.5820 - val_auc: 0.6223 - val_prc: 0.6183\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 5s 630ms/step - loss: 0.0341 - acc: 0.9957 - tp: 549.1250 - fp: 2.6250 - tn: 549.1250 - fn: 2.6250 - accuracy: 0.9957 - precision: 0.9957 - recall: 0.9957 - auc: 0.9995 - prc: 0.9995 - val_loss: 1.4587 - val_acc: 0.6133 - val_tp: 157.0000 - val_fp: 99.0000 - val_tn: 157.0000 - val_fn: 99.0000 - val_accuracy: 0.6133 - val_precision: 0.6133 - val_recall: 0.6133 - val_auc: 0.6878 - val_prc: 0.6614\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 5s 649ms/step - loss: 0.0346 - acc: 0.9916 - tp: 522.2500 - fp: 4.7500 - tn: 522.2500 - fn: 4.7500 - accuracy: 0.9916 - precision: 0.9916 - recall: 0.9916 - auc: 0.9997 - prc: 0.9997 - val_loss: 1.5720 - val_acc: 0.6133 - val_tp: 157.0000 - val_fp: 99.0000 - val_tn: 157.0000 - val_fn: 99.0000 - val_accuracy: 0.6133 - val_precision: 0.6133 - val_recall: 0.6133 - val_auc: 0.6775 - val_prc: 0.6517\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 5s 629ms/step - loss: 0.0207 - acc: 0.9974 - tp: 549.8750 - fp: 1.8750 - tn: 549.8750 - fn: 1.8750 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.8738 - val_acc: 0.5586 - val_tp: 143.0000 - val_fp: 113.0000 - val_tn: 143.0000 - val_fn: 113.0000 - val_accuracy: 0.5586 - val_precision: 0.5586 - val_recall: 0.5586 - val_auc: 0.6141 - val_prc: 0.6031\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 5s 624ms/step - loss: 0.0170 - acc: 0.9949 - tp: 541.1250 - fp: 2.3750 - tn: 541.1250 - fn: 2.3750 - accuracy: 0.9949 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6022 - val_acc: 0.6367 - val_tp: 163.0000 - val_fp: 93.0000 - val_tn: 163.0000 - val_fn: 93.0000 - val_accuracy: 0.6367 - val_precision: 0.6367 - val_recall: 0.6367 - val_auc: 0.6767 - val_prc: 0.6612\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 5s 618ms/step - loss: 0.0167 - acc: 0.9958 - tp: 529.1250 - fp: 2.0000 - tn: 529.1250 - fn: 2.0000 - accuracy: 0.9958 - precision: 0.9958 - recall: 0.9958 - auc: 0.9999 - prc: 0.9999 - val_loss: 1.6666 - val_acc: 0.6641 - val_tp: 170.0000 - val_fp: 86.0000 - val_tn: 170.0000 - val_fn: 86.0000 - val_accuracy: 0.6641 - val_precision: 0.6641 - val_recall: 0.6641 - val_auc: 0.6718 - val_prc: 0.6373\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 5s 625ms/step - loss: 0.0196 - acc: 0.9960 - tp: 529.1250 - fp: 2.0000 - tn: 529.1250 - fn: 2.0000 - accuracy: 0.9960 - precision: 0.9960 - recall: 0.9960 - auc: 0.9998 - prc: 0.9998 - val_loss: 1.8441 - val_acc: 0.6133 - val_tp: 157.0000 - val_fp: 99.0000 - val_tn: 157.0000 - val_fn: 99.0000 - val_accuracy: 0.6133 - val_precision: 0.6133 - val_recall: 0.6133 - val_auc: 0.6505 - val_prc: 0.6240\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 5s 629ms/step - loss: 0.0160 - acc: 0.9978 - tp: 546.1250 - fp: 1.5000 - tn: 546.1250 - fn: 1.5000 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.7900 - val_acc: 0.6289 - val_tp: 161.0000 - val_fp: 95.0000 - val_tn: 161.0000 - val_fn: 95.0000 - val_accuracy: 0.6289 - val_precision: 0.6289 - val_recall: 0.6289 - val_auc: 0.6521 - val_prc: 0.6201\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 5s 632ms/step - loss: 0.0124 - acc: 1.0000 - tp: 539.3750 - fp: 0.0000e+00 - tn: 539.3750 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5343 - val_acc: 0.6484 - val_tp: 166.0000 - val_fp: 90.0000 - val_tn: 166.0000 - val_fn: 90.0000 - val_accuracy: 0.6484 - val_precision: 0.6484 - val_recall: 0.6484 - val_auc: 0.7149 - val_prc: 0.7103\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 5s 627ms/step - loss: 0.0134 - acc: 0.9972 - tp: 530.1250 - fp: 1.0000 - tn: 530.1250 - fn: 1.0000 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6257 - val_acc: 0.5938 - val_tp: 152.0000 - val_fp: 104.0000 - val_tn: 152.0000 - val_fn: 104.0000 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 0.5938 - val_auc: 0.6917 - val_prc: 0.6862\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 5s 619ms/step - loss: 0.0092 - acc: 1.0000 - tp: 539.3750 - fp: 0.0000e+00 - tn: 539.3750 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.2780 - val_acc: 0.6906 - val_tp: 154.0000 - val_fp: 69.0000 - val_tn: 154.0000 - val_fn: 69.0000 - val_accuracy: 0.6906 - val_precision: 0.6906 - val_recall: 0.6906 - val_auc: 0.7418 - val_prc: 0.7109\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 5s 640ms/step - loss: 0.0104 - acc: 0.9973 - tp: 534.2500 - fp: 1.0000 - tn: 534.2500 - fn: 1.0000 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5994 - val_acc: 0.6367 - val_tp: 163.0000 - val_fp: 93.0000 - val_tn: 163.0000 - val_fn: 93.0000 - val_accuracy: 0.6367 - val_precision: 0.6367 - val_recall: 0.6367 - val_auc: 0.7035 - val_prc: 0.6769\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 5s 627ms/step - loss: 0.0079 - acc: 1.0000 - tp: 531.1250 - fp: 0.0000e+00 - tn: 531.1250 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5994 - val_acc: 0.6523 - val_tp: 167.0000 - val_fp: 89.0000 - val_tn: 167.0000 - val_fn: 89.0000 - val_accuracy: 0.6523 - val_precision: 0.6523 - val_recall: 0.6523 - val_auc: 0.6917 - val_prc: 0.6589\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 5s 617ms/step - loss: 0.0084 - acc: 0.9993 - tp: 530.6250 - fp: 0.5000 - tn: 530.6250 - fn: 0.5000 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9993 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4204 - val_acc: 0.6771 - val_tp: 151.0000 - val_fp: 72.0000 - val_tn: 151.0000 - val_fn: 72.0000 - val_accuracy: 0.6771 - val_precision: 0.6771 - val_recall: 0.6771 - val_auc: 0.7322 - val_prc: 0.7037\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 5s 658ms/step - loss: 0.0109 - acc: 0.9982 - tp: 530.2500 - fp: 0.8750 - tn: 530.2500 - fn: 0.8750 - accuracy: 0.9982 - precision: 0.9982 - recall: 0.9982 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5784 - val_acc: 0.6367 - val_tp: 163.0000 - val_fp: 93.0000 - val_tn: 163.0000 - val_fn: 93.0000 - val_accuracy: 0.6367 - val_precision: 0.6367 - val_recall: 0.6367 - val_auc: 0.6895 - val_prc: 0.6620\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 5s 616ms/step - loss: 0.0061 - acc: 0.9988 - tp: 551.0000 - fp: 0.7500 - tn: 551.0000 - fn: 0.7500 - accuracy: 0.9988 - precision: 0.9988 - recall: 0.9988 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5160 - val_acc: 0.6906 - val_tp: 154.0000 - val_fp: 69.0000 - val_tn: 154.0000 - val_fn: 69.0000 - val_accuracy: 0.6906 - val_precision: 0.6906 - val_recall: 0.6906 - val_auc: 0.7190 - val_prc: 0.6812\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 5s 624ms/step - loss: 0.0066 - acc: 1.0000 - tp: 531.1250 - fp: 0.0000e+00 - tn: 531.1250 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.0517 - val_acc: 0.5938 - val_tp: 152.0000 - val_fp: 104.0000 - val_tn: 152.0000 - val_fn: 104.0000 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 0.5938 - val_auc: 0.6726 - val_prc: 0.6575\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 5s 615ms/step - loss: 0.0041 - acc: 1.0000 - tp: 551.7500 - fp: 0.0000e+00 - tn: 551.7500 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5668 - val_acc: 0.6906 - val_tp: 154.0000 - val_fp: 69.0000 - val_tn: 154.0000 - val_fn: 69.0000 - val_accuracy: 0.6906 - val_precision: 0.6906 - val_recall: 0.6906 - val_auc: 0.7572 - val_prc: 0.7323\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 5s 618ms/step - loss: 0.0041 - acc: 1.0000 - tp: 531.1250 - fp: 0.0000e+00 - tn: 531.1250 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9004 - val_acc: 0.6502 - val_tp: 145.0000 - val_fp: 78.0000 - val_tn: 145.0000 - val_fn: 78.0000 - val_accuracy: 0.6502 - val_precision: 0.6502 - val_recall: 0.6502 - val_auc: 0.6935 - val_prc: 0.6594\n",
      "Epoch 00032: early stopping\n",
      "2/2 [==============================] - 1s 166ms/step - loss: 2.1792 - acc: 0.5938 - tp: 152.0000 - fp: 104.0000 - tn: 152.0000 - fn: 104.0000 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - auc: 0.6577 - prc: 0.6289\n"
     ]
    }
   ],
   "source": [
    "imagedir = '../../../../data/hip_images_marta/'\n",
    "csvfilename = '../../../../data/hip_images_marta/final_data.csv'\n",
    "\n",
    "# Generate datasets \n",
    "data = DataGenerator(width=WIDTH, height=HEIGHT, channels=CHANNELS, imagedir=imagedir, csvfilename=csvfilename, batch_size=batch_size)\n",
    "print('Train Size: ' + str(data.train_size) + ' Test Size: ' + str(data.test_size))\n",
    "    \n",
    "# Train model \n",
    "print(\"Training ResNet2 ...\")\n",
    "start = time.time()\n",
    "model, train_history, test_metrics = TrainResNet(data)\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074a90d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'tp', 'fp', 'tn', 'fn', 'accuracy', 'precision', 'recall', 'auc', 'prc', 'val_loss', 'val_acc', 'val_tp', 'val_fp', 'val_tn', 'val_fn', 'val_accuracy', 'val_precision', 'val_recall', 'val_auc', 'val_prc'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752b121",
   "metadata": {},
   "source": [
    "Ploting and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626eaceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plots metric history data for training a model \n",
    "'''\n",
    "def plot(data, model_name, summary, file_time):\n",
    "    # Plot Accuracy / Loss \n",
    "    fig, axs = plt.subplots(2)\n",
    "    fig.suptitle(model_name + ': ' + summary)\n",
    "\n",
    "    axs[0].plot(data[0].history['acc'])\n",
    "    axs[0].plot(data[0].history['val_acc'])\n",
    "    axs[0].set_ylabel('acc')\n",
    "    axs[0].legend([\"Train\", \"Test\"], loc=\"lower right\")\n",
    "\n",
    "    axs[1].plot(data[0].history['loss'])\n",
    "    axs[1].plot(data[0].history['val_loss'])\n",
    "    axs[1].set_ylabel('loss')\n",
    "    axs[1].legend([\"Train\", \"Test\"], loc=\"upper right\")\n",
    "    \n",
    "    #plt.show()\n",
    "    plt.savefig('hip_classify_' + model_name + file_time + '.png')\n",
    "\n",
    "'''\n",
    "Saves training and test metrics to metrics.npy\n",
    "'''\n",
    "def save_metrics(model_name, history, metrics, file_time):\n",
    "    fname = 'metrics' + file_time + '.npy' \n",
    "    fileExists = os.path.isfile(fname)\n",
    "    if(fileExists):\n",
    "        data = np.load(fname, allow_pickle=True)[()]\n",
    "        data[model_name] = { 'train_history': history.history, 'test_metrics': metrics }\n",
    "    else:\n",
    "        data = { model_name: { 'train_history': history.history, 'test_metrics': metrics } }\n",
    "    \n",
    "    np.save(fname, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a4fe8c",
   "metadata": {},
   "source": [
    "Plot and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64eeaeda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet: Loss: 0.082939, Accuracy: 0.972656, Time: 2302.78s\n",
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "file_time = datetime.datetime.today().strftime('_%Y-%m-%d__%I-%M')\n",
    "\n",
    "# Plot and Output results\n",
    "summary = 'Loss: %.6f, Accuracy: %.6f, Time: %.2fs' % (test_metrics[0], test_metrics[1], (end - start))\n",
    "print('ResNet: ' + summary)\n",
    "plot([train_history], 'ResNet', summary, file_time)\n",
    "\n",
    "# Save train_history and test_metrics\n",
    "test_metrics = { 'loss': test_metrics[0], 'acc': test_metrics[1], 'time': (end - start) }\n",
    "save_metrics('ResNet', train_history, test_metrics, file_time)\n",
    "\n",
    "# Save model\n",
    "model.save('v4_resnet_' + file_time + '.h5', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8caea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a528c30aadbad5f7d973b9ac7c75844666168a13cabc45875d9a03b5265f28e9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
