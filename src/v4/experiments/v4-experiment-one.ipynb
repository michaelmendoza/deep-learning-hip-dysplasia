{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d1ac6f",
   "metadata": {},
   "source": [
    "Hip Dysplasia Classification\n",
    "\n",
    "v4 - Experiment One - Based on code from ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d040b04",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414f47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import time\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from data_loader import DataGenerator\n",
    "from models import resnet2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7a1356",
   "metadata": {},
   "source": [
    "Model Architecture is a ResNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2a0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet2(HEIGHT, WIDTH, CHANNELS, NUM_OUTPUTS):\n",
    "\n",
    "    he_init = keras.initializers.he_normal(seed=None)\n",
    "\n",
    "    def res_net_block(input_data, filters, kernel_size, strides=1):\n",
    "        x = layers.Conv2D(filters, kernel_size, strides=strides, padding='same', activation='relu', kernel_initializer=he_init)(input_data)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(filters, kernel_size, padding='same', activation=None, kernel_initializer=he_init)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        if(strides == 2):  # add linear projection residual shortcut connection to match changed dims\n",
    "            input_data = layers.Conv2D(filters, 1, strides=strides, padding='same', activation=None, kernel_initializer=he_init)(input_data)\n",
    "        x = layers.Add()([x, input_data])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    inputs = keras.Input(shape=(HEIGHT, WIDTH, CHANNELS))\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu', kernel_initializer=he_init)(inputs)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu', kernel_initializer=he_init)(x)\n",
    "    x = layers.MaxPooling2D(3)(x)\n",
    "\n",
    "    num_filters = 64\n",
    "    for stage in range(3):\n",
    "        if(stage == 0):\n",
    "            x = res_net_block(x, num_filters, 3)\n",
    "        else:\n",
    "            x = res_net_block(x, num_filters, 3, strides=2)\n",
    "        x = res_net_block(x, num_filters, 3)\n",
    "        x = res_net_block(x, num_filters, 3)\n",
    "        x = res_net_block(x, num_filters, 3)\n",
    "        x = res_net_block(x, num_filters, 3)\n",
    "        num_filters *= 2\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(1000, activation='relu', kernel_initializer=he_init)(x)\n",
    "    outputs = layers.Dense(NUM_OUTPUTS, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    layer_count = sum([model.layers[i].name.count('conv') for i in range(len(model.layers))])\n",
    "    print(\"Number of conv layers in the model: \", layer_count)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e8e145",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86be7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "epochs = 200\n",
    "batch_size = 128 \n",
    "\n",
    "# Network Parameters\n",
    "useTransferLearning = False\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "CHANNELS = 3 if useTransferLearning else 1 \n",
    "NUM_OUTPUTS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887410b0",
   "metadata": {},
   "source": [
    "Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827accba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Trains model using input dataset. Currently uses Adam optimizer, and early stopping in training. Outputs model, train_history, and test metrics\n",
    "'''\n",
    "def TrainResNet(dataset):\n",
    "\n",
    "    earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', verbose=1, patience=25)\n",
    "\n",
    "    model = resnet2(HEIGHT, WIDTH, CHANNELS, NUM_OUTPUTS)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['acc'])\n",
    "    model.summary()\n",
    "    \n",
    "    # Train and Evaluate model\n",
    "    training_steps = round(data.train_size / batch_size)\n",
    "    validation_steps = round(data.test_size / batch_size)\n",
    "    train_history = model.fit(dataset.train_dataset, epochs=epochs, steps_per_epoch=training_steps,\n",
    "            validation_data=dataset.valid_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=[earlyStopping])\n",
    "    \n",
    "    # Evaluate Test Data \n",
    "    steps = round(data.test_size / (batch_size))\n",
    "    test_metrics = model.evaluate(dataset.test_dataset, batch_size=batch_size, steps=steps)\n",
    "    \n",
    "    return model, train_history, test_metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d3208",
   "metadata": {},
   "source": [
    "Ploting and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4adff9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plots metric history data for training a model \n",
    "'''\n",
    "def plot(data, model_name, summary):\n",
    "    # Plot Accuracy / Loss \n",
    "    fig, axs = plt.subplots(2)\n",
    "    fig.suptitle(model_name + ': ' + summary)\n",
    "\n",
    "    axs[0].plot(data[0].history['acc'])\n",
    "    axs[0].plot(data[0].history['val_acc'])\n",
    "    axs[0].set_ylabel('acc')\n",
    "    axs[0].legend([\"Train\", \"Test\"], loc=\"lower right\")\n",
    "\n",
    "    axs[1].plot(data[0].history['loss'])\n",
    "    axs[1].plot(data[0].history['val_loss'])\n",
    "    axs[1].set_ylabel('loss')\n",
    "    axs[1].legend([\"Train\", \"Test\"], loc=\"upper right\")\n",
    "    \n",
    "    #plt.show()\n",
    "    plt.savefig('hip_classify_' + model_name +'.png')\n",
    "\n",
    "'''\n",
    "Saves training and test metrics to metrics.npy\n",
    "'''\n",
    "def load_and_save(model_name, history, metrics):\n",
    "    fname = 'metrics.npy' \n",
    "    fileExists = os.path.isfile(fname)\n",
    "    if(fileExists):\n",
    "        data = np.load(fname, allow_pickle=True)[()]\n",
    "        data[model_name] = { 'train_history': history.history, 'test_metrics': metrics }\n",
    "    else:\n",
    "        data = { model_name: { 'train_history': history.history, 'test_metrics': metrics } }\n",
    "    \n",
    "    np.save(fname, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3ee618",
   "metadata": {},
   "source": [
    "Run Training and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb86723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▎                                                                            | 31/1079 [00:00<00:03, 298.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and formating image data ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1079/1079 [00:37<00:00, 28.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: Input Data (863, 500, 500, 1)  Truth Data: (863, 2)\n",
      "Test data size: Input Data (216, 500, 500, 1)  Truth Data: (216, 2)\n",
      "Loading and formating image data: Complete\n",
      "Train Size: 863 Test Size: 216\n",
      "Training ResNet2 ...\n",
      "Number of conv layers in the model:  34\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 18496       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 85, 85, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 85, 85, 64)   36928       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 85, 85, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 85, 85, 64)   36928       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 85, 85, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 85, 85, 64)   0           batch_normalization_1[0][0]      \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 85, 85, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 85, 85, 64)   36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 85, 85, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 85, 85, 64)   36928       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 85, 85, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 85, 85, 64)   0           batch_normalization_3[0][0]      \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 85, 85, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 85, 85, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 85, 85, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 85, 85, 64)   36928       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 85, 85, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 85, 85, 64)   0           batch_normalization_5[0][0]      \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 85, 85, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 85, 85, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 85, 85, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 85, 85, 64)   36928       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 85, 85, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 85, 85, 64)   0           batch_normalization_7[0][0]      \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 85, 85, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 85, 85, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 85, 85, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 85, 85, 64)   36928       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 85, 85, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 85, 85, 64)   0           batch_normalization_9[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 85, 85, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 43, 43, 128)  73856       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 43, 43, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 43, 43, 128)  147584      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 43, 43, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 43, 43, 128)  8320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 43, 43, 128)  0           batch_normalization_11[0][0]     \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 43, 43, 128)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 43, 43, 128)  147584      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 43, 43, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 43, 43, 128)  147584      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 43, 43, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 43, 43, 128)  0           batch_normalization_13[0][0]     \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 43, 43, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 43, 43, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 43, 43, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 43, 43, 128)  147584      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 43, 43, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 43, 43, 128)  0           batch_normalization_15[0][0]     \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 43, 43, 128)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 43, 43, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 43, 43, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 43, 43, 128)  147584      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 43, 43, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 43, 43, 128)  0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 43, 43, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 43, 43, 128)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 43, 43, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 43, 43, 128)  147584      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 43, 43, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 43, 43, 128)  0           batch_normalization_19[0][0]     \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 43, 43, 128)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 22, 22, 256)  295168      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 22, 22, 256)  1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 22, 22, 256)  590080      batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 22, 22, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 22, 22, 256)  33024       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 22, 22, 256)  0           batch_normalization_21[0][0]     \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 22, 22, 256)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 22, 22, 256)  590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 22, 22, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 22, 22, 256)  590080      batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 22, 22, 256)  1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 22, 22, 256)  0           batch_normalization_23[0][0]     \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 22, 22, 256)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 22, 22, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 22, 22, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 22, 22, 256)  590080      batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 22, 22, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 22, 22, 256)  0           batch_normalization_25[0][0]     \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 22, 22, 256)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 22, 22, 256)  590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 22, 22, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 22, 22, 256)  590080      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 22, 22, 256)  1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 22, 22, 256)  0           batch_normalization_27[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 22, 22, 256)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 22, 22, 256)  590080      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 22, 22, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 22, 22, 256)  590080      batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 22, 22, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 22, 22, 256)  0           batch_normalization_29[0][0]     \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 22, 22, 256)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 256)          0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1000)         257000      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2002        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 7,714,362\n",
      "Trainable params: 7,705,402\n",
      "Non-trainable params: 8,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 15s 1s/step - loss: 5.4116 - acc: 0.5023 - val_loss: 43504.1172 - val_acc: 0.6278\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 6s 724ms/step - loss: 0.9390 - acc: 0.5005 - val_loss: 53530.4531 - val_acc: 0.5938\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 6s 742ms/step - loss: 0.7742 - acc: 0.6433 - val_loss: 5147.5840 - val_acc: 0.3867\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 6s 716ms/step - loss: 0.5960 - acc: 0.7343 - val_loss: 7382.9600 - val_acc: 0.6641\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 6s 750ms/step - loss: 0.5308 - acc: 0.7478 - val_loss: 4868.0889 - val_acc: 0.5938\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 6s 734ms/step - loss: 0.5184 - acc: 0.7399 - val_loss: 1253.7815 - val_acc: 0.6641\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 6s 720ms/step - loss: 0.3838 - acc: 0.8357 - val_loss: 566.5983 - val_acc: 0.5938\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 6s 725ms/step - loss: 0.2725 - acc: 0.8794 - val_loss: 183.3937 - val_acc: 0.5938\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 6s 729ms/step - loss: 0.1960 - acc: 0.9251 - val_loss: 47.5573 - val_acc: 0.6133\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 6s 746ms/step - loss: 0.1430 - acc: 0.9482 - val_loss: 64.8330 - val_acc: 0.6278\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 6s 750ms/step - loss: 0.3185 - acc: 0.8750 - val_loss: 41.6496 - val_acc: 0.6289\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 6s 714ms/step - loss: 0.2571 - acc: 0.8926 - val_loss: 84.4060 - val_acc: 0.6906\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 6s 731ms/step - loss: 0.1655 - acc: 0.9399 - val_loss: 32.1183 - val_acc: 0.5820\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 6s 735ms/step - loss: 0.1726 - acc: 0.9338 - val_loss: 7.5245 - val_acc: 0.6771\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 6s 732ms/step - loss: 0.0544 - acc: 0.9883 - val_loss: 19.6406 - val_acc: 0.6523\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 6s 722ms/step - loss: 0.0307 - acc: 0.9911 - val_loss: 10.8998 - val_acc: 0.6289\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 6s 724ms/step - loss: 0.0309 - acc: 0.9915 - val_loss: 4.9023 - val_acc: 0.6445\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 6s 730ms/step - loss: 0.0535 - acc: 0.9835 - val_loss: 12.5714 - val_acc: 0.3945\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 6s 722ms/step - loss: 0.0265 - acc: 0.9916 - val_loss: 21.9265 - val_acc: 0.3984\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 6s 744ms/step - loss: 0.0483 - acc: 0.9809 - val_loss: 26.1115 - val_acc: 0.3184\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 6s 743ms/step - loss: 0.0498 - acc: 0.9808 - val_loss: 6.3610 - val_acc: 0.6641\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 6s 724ms/step - loss: 0.0326 - acc: 0.9884 - val_loss: 4.8411 - val_acc: 0.5938\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 6s 746ms/step - loss: 0.0571 - acc: 0.9795 - val_loss: 4.5943 - val_acc: 0.3750\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 6s 722ms/step - loss: 0.1176 - acc: 0.9566 - val_loss: 6.9269 - val_acc: 0.5078\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 6s 721ms/step - loss: 0.1268 - acc: 0.9486 - val_loss: 7.0198 - val_acc: 0.6906\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 6s 719ms/step - loss: 0.1273 - acc: 0.9523 - val_loss: 9.3750 - val_acc: 0.6367\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 6s 725ms/step - loss: 0.0517 - acc: 0.9840 - val_loss: 2.1316 - val_acc: 0.6172\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 6s 736ms/step - loss: 0.0318 - acc: 0.9920 - val_loss: 1.1847 - val_acc: 0.7489\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 6s 725ms/step - loss: 0.0097 - acc: 0.9950 - val_loss: 2.5849 - val_acc: 0.6367\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 6s 722ms/step - loss: 0.0050 - acc: 0.9993 - val_loss: 1.4406 - val_acc: 0.7305\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 6s 723ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5919 - val_acc: 0.8555\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 6s 729ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.4246 - val_acc: 0.8867\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 6s 724ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.1545 - val_acc: 0.9336\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 6s 728ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8750\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 6s 736ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 0.9552\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 6s 722ms/step - loss: 3.8012e-04 - acc: 1.0000 - val_loss: 0.0313 - val_acc: 0.9922\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 6s 744ms/step - loss: 2.8693e-04 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 0.9865\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 6s 742ms/step - loss: 2.9490e-04 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 0.9883\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 6s 731ms/step - loss: 2.0377e-04 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 6s 753ms/step - loss: 1.6301e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9961\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 6s 726ms/step - loss: 1.4872e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 6s 732ms/step - loss: 1.2915e-04 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 0.9955\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 6s 731ms/step - loss: 1.0923e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 6s 738ms/step - loss: 1.0504e-04 - acc: 1.0000 - val_loss: 9.4784e-04 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 6s 747ms/step - loss: 9.3601e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 6s 735ms/step - loss: 8.7489e-05 - acc: 1.0000 - val_loss: 9.1068e-04 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 6s 731ms/step - loss: 7.9649e-05 - acc: 1.0000 - val_loss: 8.3567e-04 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 6s 727ms/step - loss: 7.1740e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 6s 736ms/step - loss: 7.2263e-05 - acc: 1.0000 - val_loss: 9.1372e-04 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 6s 735ms/step - loss: 6.3898e-05 - acc: 1.0000 - val_loss: 7.7024e-04 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 6s 733ms/step - loss: 6.6596e-05 - acc: 1.0000 - val_loss: 4.2890e-04 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 6s 737ms/step - loss: 6.6769e-05 - acc: 1.0000 - val_loss: 9.7061e-04 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 6s 733ms/step - loss: 6.0720e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 6s 738ms/step - loss: 5.9298e-05 - acc: 1.0000 - val_loss: 4.3036e-04 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 6s 738ms/step - loss: 6.1896e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 6s 737ms/step - loss: 5.2149e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 6s 737ms/step - loss: 5.0623e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 6s 735ms/step - loss: 4.9216e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 6s 755ms/step - loss: 4.9447e-05 - acc: 1.0000 - val_loss: 4.7919e-04 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 20s 3s/step - loss: 4.4765e-05 - acc: 1.0000 - val_loss: 3.1339e-04 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 4.4678e-05 - acc: 1.0000 - val_loss: 4.7269e-04 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 4.3497e-05 - acc: 1.0000 - val_loss: 1.5291e-04 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 33s 5s/step - loss: 4.8077e-05 - acc: 1.0000 - val_loss: 3.2393e-04 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 61s 8s/step - loss: 3.9393e-05 - acc: 1.0000 - val_loss: 3.3566e-04 - val_acc: 1.0000\n",
      "Epoch 00064: early stopping\n",
      "2/2 [==============================] - 13s 6s/step - loss: 0.0019 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "imagedir = '../../../../data/hip_images_marta/'\n",
    "csvfilename = '../../../../data/hip_images_marta/final_data.csv'\n",
    "\n",
    "# Generate datasets \n",
    "data = DataGenerator(width=WIDTH, height=HEIGHT, channels=CHANNELS, imagedir=imagedir, csvfilename=csvfilename, batch_size=batch_size)\n",
    "print('Train Size: ' + str(data.train_size) + ' Test Size: ' + str(data.test_size))\n",
    "    \n",
    "# Train model \n",
    "print(\"Training ResNet2 ...\")\n",
    "start = time.time()\n",
    "model, train_history, test_metrics = TrainResNet(data)\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13167890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet: Loss: 0.001917, Accuracy: 1.000000, Time: 530.39s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and Output results\n",
    "summary = 'Loss: %.6f, Accuracy: %.6f, Time: %.2fs' % (test_metrics[0], test_metrics[1], (end - start))\n",
    "print('ResNet: ' + summary)\n",
    "plot([train_history], 'ResNet', summary)\n",
    "\n",
    "# Save train_history and test_metrics\n",
    "test_metrics = { 'loss': test_metrics[0], 'acc': test_metrics[1], 'time': (end - start) }\n",
    "load_and_save('ResNet', train_history, test_metrics)\n",
    "\n",
    "# Save model\n",
    "import datetime\n",
    "file_time = datetime.datetime.today().strftime('_%Y-%m-%d__%I-%M')\n",
    "model.save('v4_resnet_keras_' + file_time + '.h5', save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
